{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVI9AtMufZemIlxEFM9zZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PendlimarriSivasankar/PS/blob/main/Pyspark_Scenario_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lnSdJWno2Nd_"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"colab pyspark\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead, col, expr\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "data = [(1111, \"2021-01-15\", 10),\n",
        "        (1111, \"2021-01-16\", 15),\n",
        "        (1111, \"2021-01-17\", 30),\n",
        "        (1112, \"2021-01-15\", 10),\n",
        "        (1112, \"2021-01-15\", 20),\n",
        "        (1112, \"2021-01-15\", 30)]\n",
        "\n",
        "myschema = [\"sensorid\", \"timestamp\", \"values\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=myschema)\n",
        "df.show()\n",
        "d1 = Window.partitionBy(\"sensorid\").orderBy(\"values\")\n",
        "\n",
        "finaldf = df.withColumn(\"nextvalues\", lead(\"values\", 1).over(d1)) \\\n",
        "    .filter(col(\"nextvalues\").isNotNull()) \\\n",
        "    .withColumn(\"values\", expr(\"nextvalues-values\")) \\\n",
        "    .drop(\"nextvalues\") \\\n",
        "    .orderBy(col(\"sensorid\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T4KZ3kA6jat",
        "outputId": "02760569-6f68-49b8-b637-53cbcf48178f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+\n",
            "|sensorid| timestamp|values|\n",
            "+--------+----------+------+\n",
            "|    1111|2021-01-15|    10|\n",
            "|    1111|2021-01-16|    15|\n",
            "|    1111|2021-01-17|    30|\n",
            "|    1112|2021-01-15|    10|\n",
            "|    1112|2021-01-15|    20|\n",
            "|    1112|2021-01-15|    30|\n",
            "+--------+----------+------+\n",
            "\n",
            "+--------+----------+------+\n",
            "|sensorid| timestamp|values|\n",
            "+--------+----------+------+\n",
            "|    1111|2021-01-15|     5|\n",
            "|    1111|2021-01-16|    15|\n",
            "|    1112|2021-01-15|    10|\n",
            "|    1112|2021-01-15|    10|\n",
            "+--------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "Person_175 = [\n",
        "    (1, \"Wang\", \"Allen\"),\n",
        "    (2, \"Alice\", \"Bob\")\n",
        "]\n",
        "\n",
        "Person_columns_175 = [\"personId\", \"lastName\", \"firstName\"]\n",
        "Person_df_175 = spark.createDataFrame(Person_175, Person_columns_175)\n",
        "Person_df_175.show()\n",
        "\n",
        "address_175 = [\n",
        "    (1, 2, \"New York City\", \"New York\"),\n",
        "    (2, 3, \"Leetcode\", \"California\")\n",
        "]\n",
        "\n",
        "address_columns_175 = [\"addressId\", \"personId\", \"city\", \"state\"]\n",
        "address_df_175 = spark.createDataFrame(address_175, address_columns_175)\n",
        "address_df_175.show()\n",
        "\n",
        "Person_175 = [\n",
        "    (1, \"Wang\", \"Allen\"),\n",
        "    (2, \"Alice\", \"Bob\")\n",
        "]\n",
        "\n",
        "Person_columns_175 = [\"personId\", \"lastName\", \"firstName\"]\n",
        "Person_df_175 = spark.createDataFrame(Person_175, Person_columns_175)\n",
        "Person_df_175.show()\n",
        "\n",
        "address_175 = [\n",
        "    (1, 2, \"New York City\", \"New York\"),\n",
        "    (2, 3, \"Leetcode\", \"California\")\n",
        "]\n",
        "\n",
        "address_columns_175 = [\"addressId\", \"personId\", \"city\", \"state\"]\n",
        "address_df_175 = spark.createDataFrame(address_175, address_columns_175)\n",
        "address_df_175.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2oIqpkYpkKd",
        "outputId": "cdd9b4d0-30a5-4a55-bd31-54c3a57c87fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+---------+\n",
            "|personId|lastName|firstName|\n",
            "+--------+--------+---------+\n",
            "|       1|    Wang|    Allen|\n",
            "|       2|   Alice|      Bob|\n",
            "+--------+--------+---------+\n",
            "\n",
            "+---------+--------+-------------+----------+\n",
            "|addressId|personId|         city|     state|\n",
            "+---------+--------+-------------+----------+\n",
            "|        1|       2|New York City|  New York|\n",
            "|        2|       3|     Leetcode|California|\n",
            "+---------+--------+-------------+----------+\n",
            "\n",
            "+--------+--------+---------+\n",
            "|personId|lastName|firstName|\n",
            "+--------+--------+---------+\n",
            "|       1|    Wang|    Allen|\n",
            "|       2|   Alice|      Bob|\n",
            "+--------+--------+---------+\n",
            "\n",
            "+---------+--------+-------------+----------+\n",
            "|addressId|personId|         city|     state|\n",
            "+---------+--------+-------------+----------+\n",
            "|        1|       2|New York City|  New York|\n",
            "|        2|       3|     Leetcode|California|\n",
            "+---------+--------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}