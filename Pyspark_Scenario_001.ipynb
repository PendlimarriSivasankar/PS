{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMztTceS4lucj+MMKUdaU1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PendlimarriSivasankar/PS/blob/main/Pyspark_Scenario_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lnSdJWno2Nd_"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"colab pyspark\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead, col, expr\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "data = [(1111, \"2021-01-15\", 10),\n",
        "        (1111, \"2021-01-16\", 15),\n",
        "        (1111, \"2021-01-17\", 30),\n",
        "        (1112, \"2021-01-15\", 10),\n",
        "        (1112, \"2021-01-15\", 20),\n",
        "        (1112, \"2021-01-15\", 30)]\n",
        "\n",
        "myschema = [\"sensorid\", \"timestamp\", \"values\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=myschema)\n",
        "df.show()\n",
        "d1 = Window.partitionBy(\"sensorid\").orderBy(\"values\")\n",
        "\n",
        "finaldf = df.withColumn(\"nextvalues\", lead(\"values\", 1).over(d1)) \\\n",
        "    .filter(col(\"nextvalues\").isNotNull()) \\\n",
        "    .withColumn(\"values\", expr(\"nextvalues-values\")) \\\n",
        "    .drop(\"nextvalues\") \\\n",
        "    .orderBy(col(\"sensorid\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T4KZ3kA6jat",
        "outputId": "02760569-6f68-49b8-b637-53cbcf48178f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+\n",
            "|sensorid| timestamp|values|\n",
            "+--------+----------+------+\n",
            "|    1111|2021-01-15|    10|\n",
            "|    1111|2021-01-16|    15|\n",
            "|    1111|2021-01-17|    30|\n",
            "|    1112|2021-01-15|    10|\n",
            "|    1112|2021-01-15|    20|\n",
            "|    1112|2021-01-15|    30|\n",
            "+--------+----------+------+\n",
            "\n",
            "+--------+----------+------+\n",
            "|sensorid| timestamp|values|\n",
            "+--------+----------+------+\n",
            "|    1111|2021-01-15|     5|\n",
            "|    1111|2021-01-16|    15|\n",
            "|    1112|2021-01-15|    10|\n",
            "|    1112|2021-01-15|    10|\n",
            "+--------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "Person = [\n",
        "    (1, \"Wang\", \"Allen\"),\n",
        "    (2, \"Alice\", \"Bob\")\n",
        "]\n",
        "\n",
        "Person_columns = [\"personId\", \"lastName\", \"firstName\"]\n",
        "Person_df = spark.createDataFrame(Person, Person_columns)\n",
        "Person_df.show()\n",
        "\n",
        "address = [\n",
        "    (1, 2, \"New York City\", \"New York\"),\n",
        "    (2, 3, \"Leetcode\", \"California\")\n",
        "]\n",
        "\n",
        "address_columns = [\"addressId\", \"personId\", \"city\", \"state\"]\n",
        "address_df = spark.createDataFrame(address, address_columns)\n",
        "address_df.show()\n",
        "\n",
        "Person = [\n",
        "    (1, \"Wang\", \"Allen\"),\n",
        "    (2, \"Alice\", \"Bob\")\n",
        "]\n",
        "\n",
        "Person_columns = [\"personId\", \"lastName\", \"firstName\"]\n",
        "Person_df = spark.createDataFrame(Person, Person_columns)\n",
        "Person_df.show()\n",
        "\n",
        "address = [\n",
        "    (1, 2, \"New York City\", \"New York\"),\n",
        "    (2, 3, \"Leetcode\", \"California\")\n",
        "]\n",
        "\n",
        "address_columns = [\"addressId\", \"personId\", \"city\", \"state\"]\n",
        "address_df = spark.createDataFrame(address, address_columns)\n",
        "address_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2oIqpkYpkKd",
        "outputId": "140037c4-0f51-435b-d8ec-459f7b89bd4c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+---------+\n",
            "|personId|lastName|firstName|\n",
            "+--------+--------+---------+\n",
            "|       1|    Wang|    Allen|\n",
            "|       2|   Alice|      Bob|\n",
            "+--------+--------+---------+\n",
            "\n",
            "+---------+--------+-------------+----------+\n",
            "|addressId|personId|         city|     state|\n",
            "+---------+--------+-------------+----------+\n",
            "|        1|       2|New York City|  New York|\n",
            "|        2|       3|     Leetcode|California|\n",
            "+---------+--------+-------------+----------+\n",
            "\n",
            "+--------+--------+---------+\n",
            "|personId|lastName|firstName|\n",
            "+--------+--------+---------+\n",
            "|       1|    Wang|    Allen|\n",
            "|       2|   Alice|      Bob|\n",
            "+--------+--------+---------+\n",
            "\n",
            "+---------+--------+-------------+----------+\n",
            "|addressId|personId|         city|     state|\n",
            "+---------+--------+-------------+----------+\n",
            "|        1|       2|New York City|  New York|\n",
            "|        2|       3|     Leetcode|California|\n",
            "+---------+--------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data = [\n",
        "    (1, 5),\n",
        "    (2, 6),\n",
        "    (3, 5),\n",
        "    (3, 6),\n",
        "    (1, 6)\n",
        "]\n",
        "\n",
        "customer_columns = [\"customer_id\", \"product_key\"]\n",
        "customer_df = spark.createDataFrame(customer_data, customer_columns)\n",
        "customer_df.show()\n",
        "\n",
        "\n",
        "product_data = [\n",
        "    (5,),\n",
        "    (6,)\n",
        "]\n",
        "product_columns = [\"product_key\"]\n",
        "product_df = spark.createDataFrame(product_data, product_columns)\n",
        "product_df.show()\n",
        "total_products = product_df.select(countDistinct(\"product_key\")).collect()[0][0]\n",
        "customer_df\\\n",
        "    .groupBy(\"customer_id\").agg(\n",
        "    countDistinct(\"product_key\").alias(\"num_products_bought\"))\\\n",
        "    .filter(\n",
        "        col(\"num_products_bought\") == total_products\n",
        "    ).select(\"customer_id\").show()"
      ],
      "metadata": {
        "id": "aIgvlwVzq7Cp",
        "outputId": "376b59ce-898a-4d9b-85f3-88deb1381631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|customer_id|product_key|\n",
            "+-----------+-----------+\n",
            "|          1|          5|\n",
            "|          2|          6|\n",
            "|          3|          5|\n",
            "|          3|          6|\n",
            "|          1|          6|\n",
            "+-----------+-----------+\n",
            "\n",
            "+-----------+\n",
            "|product_key|\n",
            "+-----------+\n",
            "|          5|\n",
            "|          6|\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|          1|\n",
            "|          3|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actor_director_data = [\n",
        "    (1, 1, 0),\n",
        "    (1, 1, 1),\n",
        "    (1, 1, 2),\n",
        "    (1, 2, 3),\n",
        "    (1, 2, 4),\n",
        "    (2, 1, 5),\n",
        "    (2, 1, 6)\n",
        "]\n",
        "\n",
        "actor_director_columns = [\"actor_id\", \"director_id\", \"timestamp\"]\n",
        "actor_director_df = spark.createDataFrame(actor_director_data, actor_director_columns)\n",
        "actor_director_df.show()\n",
        "actor_director_df\\\n",
        "    .groupBy(\"actor_id\", \"director_id\")\\\n",
        "    .agg(count(\"*\").alias(\"cooperations\"))\\\n",
        "    .filter(col(\"cooperations\") >= 3)\\\n",
        "    .select(\"actor_id\", \"director_id\").show()"
      ],
      "metadata": {
        "id": "e3vM24irrcGv",
        "outputId": "eb56c73c-f218-498c-bf9b-864ce458bacb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+---------+\n",
            "|actor_id|director_id|timestamp|\n",
            "+--------+-----------+---------+\n",
            "|       1|          1|        0|\n",
            "|       1|          1|        1|\n",
            "|       1|          1|        2|\n",
            "|       1|          2|        3|\n",
            "|       1|          2|        4|\n",
            "|       2|          1|        5|\n",
            "|       2|          1|        6|\n",
            "+--------+-----------+---------+\n",
            "\n",
            "+--------+-----------+\n",
            "|actor_id|director_id|\n",
            "+--------+-----------+\n",
            "|       1|          1|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data = [\n",
        "    (1, 100, 2008, 10, 5000),\n",
        "    (2, 100, 2009, 12, 5000),\n",
        "    (7, 200, 2011, 15, 9000)\n",
        "]\n",
        "\n",
        "sales_columns = [\"sale_id\", \"product_id\", \"year\", \"quantity\", \"price\"]\n",
        "sales_df = spark.createDataFrame(sales_data, sales_columns)\n",
        "sales_df.show()\n",
        "\n",
        "product_data = [\n",
        "    (100, \"Nokia\"),\n",
        "    (200, \"Apple\"),\n",
        "    (300, \"Samsung\")\n",
        "]\n",
        "\n",
        "product_columns = [\"product_id\", \"product_name\"]\n",
        "product_df = spark.createDataFrame(product_data, product_columns)\n",
        "product_df.show()\n",
        "\n",
        "sales_df\\\n",
        "    .join(product_df, on=\"product_id\", how=\"inner\")\\\n",
        "    .select(\"product_name\", \"year\", \"price\").show()"
      ],
      "metadata": {
        "id": "bLlqrs2NswcL",
        "outputId": "dc5d576c-f0d2-47e8-acd5-322fff2d1f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+----+--------+-----+\n",
            "|sale_id|product_id|year|quantity|price|\n",
            "+-------+----------+----+--------+-----+\n",
            "|      1|       100|2008|      10| 5000|\n",
            "|      2|       100|2009|      12| 5000|\n",
            "|      7|       200|2011|      15| 9000|\n",
            "+-------+----------+----+--------+-----+\n",
            "\n",
            "+----------+------------+\n",
            "|product_id|product_name|\n",
            "+----------+------------+\n",
            "|       100|       Nokia|\n",
            "|       200|       Apple|\n",
            "|       300|     Samsung|\n",
            "+----------+------------+\n",
            "\n",
            "+------------+----+-----+\n",
            "|product_name|year|price|\n",
            "+------------+----+-----+\n",
            "|       Nokia|2008| 5000|\n",
            "|       Nokia|2009| 5000|\n",
            "|       Apple|2011| 9000|\n",
            "+------------+----+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}